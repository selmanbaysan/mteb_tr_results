{
  "dataset_revision": "main",
  "task_name": "TurkishOffensiveLanguageClassification",
  "mteb_version": "1.31.3",
  "scores": {
    "test": [
      {
        "accuracy": 0.685149,
        "f1": 0.614251,
        "f1_weighted": 0.710679,
        "ap": 0.302385,
        "ap_weighted": 0.302385,
        "scores_per_experiment": [
          {
            "accuracy": 0.742248,
            "f1": 0.675413,
            "f1_weighted": 0.763115,
            "ap": 0.357071,
            "ap_weighted": 0.357071
          },
          {
            "accuracy": 0.73542,
            "f1": 0.624731,
            "f1_weighted": 0.746088,
            "ap": 0.285648,
            "ap_weighted": 0.285648
          },
          {
            "accuracy": 0.770413,
            "f1": 0.709649,
            "f1_weighted": 0.78874,
            "ap": 0.401537,
            "ap_weighted": 0.401537
          },
          {
            "accuracy": 0.551351,
            "f1": 0.513871,
            "f1_weighted": 0.594246,
            "ap": 0.243444,
            "ap_weighted": 0.243444
          },
          {
            "accuracy": 0.67909,
            "f1": 0.62851,
            "f1_weighted": 0.710132,
            "ap": 0.324437,
            "ap_weighted": 0.324437
          },
          {
            "accuracy": 0.694168,
            "f1": 0.631034,
            "f1_weighted": 0.721914,
            "ap": 0.315236,
            "ap_weighted": 0.315236
          },
          {
            "accuracy": 0.737411,
            "f1": 0.652954,
            "f1_weighted": 0.754897,
            "ap": 0.322142,
            "ap_weighted": 0.322142
          },
          {
            "accuracy": 0.682504,
            "f1": 0.604752,
            "f1_weighted": 0.709136,
            "ap": 0.282066,
            "ap_weighted": 0.282066
          },
          {
            "accuracy": 0.555334,
            "f1": 0.507447,
            "f1_weighted": 0.598896,
            "ap": 0.231357,
            "ap_weighted": 0.231357
          },
          {
            "accuracy": 0.703556,
            "f1": 0.59415,
            "f1_weighted": 0.719622,
            "ap": 0.260912,
            "ap_weighted": 0.260912
          }
        ],
        "main_score": 0.685149,
        "hf_subset": "default",
        "languages": [
          "tur-Latn"
        ]
      }
    ]
  },
  "evaluation_time": 13.349059104919434,
  "kg_co2_emissions": null
}